{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPFEJrLLbZe0"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "## Instructions\n",
        "- Run this notebook on ```Google Colab(preferable)```\n",
        "- Write your code and analysis in the indicated cells.\n",
        "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
        "- Do not attempt to change the contents of other cells. \n",
        "\n",
        "## Packages Used\n",
        "- sklearn [link](https://scikit-learn.org/)\n",
        "- Keras [link](https://keras.io/guides/)\n",
        "\n",
        "## Submission\n",
        "- Rename the notebook to `<roll_number>_Assignment3_Q3.ipynb`.\n",
        "\n",
        "\n",
        "## Question 3\n",
        "Fake news is a widespread problem and there are many methods for combating it.\n",
        "You have to build a fake news detection system using a ML model. Train any ML model (ANN, LSTM) over the given Dataset.\n",
        "The dataset has short statements spoken by people and has the meta-information and corresponding label for those sentences. \n",
        "Your target is label column which has 6 labels(in the increasing order of truthfullness): pants-fire, false, barely-true, half-true, mostly-true, true.\n",
        "\n",
        "The features are 'statement', 'subject', 'speaker', 'job', 'state', 'party', 'barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c', 'pants_on_fire_c', 'venue' and the target is column \"label\".\n",
        "\n",
        "The statement is made by speaker whose job, party are given along with 6 columns which are an account of the  type of news(labels) the person has shared before. \n",
        "The person who has shared fake content before is likely to share it in future and this can be accounted by the ML model as a feature. Column barely_true_c contains how many barely_true news has the speaker shared (and so is with column X_c, value of X_c is number of X the person shared).\n",
        "\n",
        "\n",
        "You have to perform two tasks:\n",
        "* task1: Binary classification <br>\n",
        "Classify the given news as true/false. Take the labels pants-fire, false, barely-true as false and rest (half-true, mostly-true, true) as true.\n",
        "* task2: Six-way classification <br>\n",
        "Classify the given news into six-classes \"pants-fire, false, barely-true, half-true, mostly-true, true\".\n",
        "\n",
        "For each of the tasks:\n",
        "1) Experiment with depth of network and try to fine-tune hyperparameters reporting your observations. <br>\n",
        "2) Report the accuracy, f1-score, confusion matrix on train, val and test sets. <br>\n",
        "3) Experiment with bag-of-words, glove and bert embeddings(code given in the below notebook) and report results. <br> Comment on what is the affect of embedding on the results.\n",
        "\n",
        "The pre-processing code is provided, you need to write the training and test.\n",
        "\n",
        "Note: You are supposed to train on trainset, fine-tune on val and just eval on test set. If found that you trained on val/test sets, the penalty will be incurred."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKoLpsvdWx26",
        "outputId": "f4056669-4c4e-45c6-cd2f-e18ded1f8693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aA2hqKTbZe7",
        "outputId": "1524daec-17ce-4fee-82cb-e8e10471f61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "# !pip install numpy\n",
        "# !pip install tensorflow\n",
        "# !pip install re\n",
        "# !pip install nltk\n",
        "# !pip install keras\n",
        "# !pip install sklearn\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agl6JEo_gaBT",
        "outputId": "fd8e3e3c-b67c-48a9-d419-4b1cc1518b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras  #feel free to use any other library\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from keras.layers import Dense,Input,LSTM\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y--6uAJJbZe_"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('q3_data/train.csv')\n",
        "val = pd.read_csv('q3_data/val.csv')\n",
        "test = pd.read_csv('q3_data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enAZ4DvUffVr"
      },
      "outputs": [],
      "source": [
        "# Dropping the 'id' column\n",
        "train.drop('id', axis = 1, inplace = True)\n",
        "test.drop('id', axis = 1, inplace = True)\n",
        "val.drop('id', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "7pEJ-G4yITrd",
        "outputId": "adc9262a-85fd-44e8-f2ac-8e70eb1f849b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         label                                          statement  \\\n",
              "0        False  Says the Annies List political group supports ...   \n",
              "1    half-true  When did the decline of coal start? It started...   \n",
              "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
              "3        False  Health care reform legislation is likely to ma...   \n",
              "4    half-true  The economic turnaround started at the end of ...   \n",
              "\n",
              "                              subject         speaker                   job  \\\n",
              "0                            abortion    dwayne-bohac  State representative   \n",
              "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
              "2                      foreign-policy    barack-obama             President   \n",
              "3                         health-care    blog-posting                   NaN   \n",
              "4                        economy,jobs   charlie-crist                   NaN   \n",
              "\n",
              "      state       party  barely_true_c  false_c  half_true_c  mostly_true_c  \\\n",
              "0     Texas  republican              0        1            0              0   \n",
              "1  Virginia    democrat              0        0            1              1   \n",
              "2  Illinois    democrat             70       71          160            163   \n",
              "3       NaN        none              7       19            3              5   \n",
              "4   Florida    democrat             15        9           20             19   \n",
              "\n",
              "   pants_on_fire_c                venue  \n",
              "0                0             a mailer  \n",
              "1                0      a floor speech.  \n",
              "2                9               Denver  \n",
              "3               44       a news release  \n",
              "4                2  an interview on CNN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dea1556-b2e4-41fa-ac2a-dbbc51cbf132\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>job</th>\n",
              "      <th>state</th>\n",
              "      <th>party</th>\n",
              "      <th>barely_true_c</th>\n",
              "      <th>false_c</th>\n",
              "      <th>half_true_c</th>\n",
              "      <th>mostly_true_c</th>\n",
              "      <th>pants_on_fire_c</th>\n",
              "      <th>venue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>9</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>a news release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>an interview on CNN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dea1556-b2e4-41fa-ac2a-dbbc51cbf132')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dea1556-b2e4-41fa-ac2a-dbbc51cbf132 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dea1556-b2e4-41fa-ac2a-dbbc51cbf132');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbFqDO8_U6df",
        "outputId": "faa6cd0b-51fd-4ee4-85bf-595f88c91f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10269, 13)\n",
            "(1284, 13)\n",
            "(1283, 13)\n"
          ]
        }
      ],
      "source": [
        "# Checking the shape of data\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYvhCM7dbZfD"
      },
      "source": [
        "## Clean and pre-process data\n",
        "* Replace missing values\n",
        "* Remove numbers and special characters\n",
        "* Convert to upper-case\n",
        "\n",
        "We experiment with two types of processing, one directly appending the other attributes like subject, job, state, party to sentence and then applying bag of words on it.\n",
        "\n",
        "Other being encoding sentence with glove embeddings and passing just that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7tTpAClApgJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dataPreprocessing(data):\n",
        "    '''Function for cleaning the dataset\n",
        "    '''\n",
        "    corpus = []\n",
        "    # Missing values\n",
        "    data[\"job\"].fillna(\"no-job\", inplace = True)\n",
        "    data[\"state\"].fillna(\"no-state\", inplace = True)\n",
        "\n",
        "    for x in range(data.shape[0]):\n",
        "        statement = re.sub('[^a-zA-Z]', ' ', data['statement'][x]) # Removing all numbers and special characters\n",
        "        statement = statement.lower() # Converting uppercase to lowercase\n",
        "        statement = statement.split()\n",
        "        \n",
        "        # you can experiment with any other stemmers\n",
        "        ps = PorterStemmer()\n",
        "        statement = [ps.stem(word) for word in statement if not word in set(stopwords.words('english'))] # Stemming the dataset and removing stopwords\n",
        "        statement = ' '.join(statement)\n",
        "        subject = data['subject'][x].replace(',', ' ')\n",
        "        speaker = data['speaker'][x]\n",
        "        job = data['job'][x].lower()\n",
        "        # job = job.replace(' ', '-')\n",
        "        state = data['state'][x].lower()\n",
        "        party = data['party'][x].lower()\n",
        "        corpus.append(statement + ' '  + subject + ' ' + job + ' ' + state + ' ' + party)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy1ikPhJ9LoS"
      },
      "outputs": [],
      "source": [
        "x_train = dataPreprocessing(train)\n",
        "x_val = dataPreprocessing(val) \n",
        "x_test = dataPreprocessing(test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt5c2viDbZfG",
        "outputId": "a1ea2305-82c8-4b37-f824-6b6ec75e0ab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 1284, 1283)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(x_train), len(x_val), len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHVCknsNbZfI"
      },
      "outputs": [],
      "source": [
        "corpus = x_train + x_val + x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGrImxxmbZfI"
      },
      "source": [
        "## Using bag-of-words embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sopw2zusZwn4"
      },
      "outputs": [],
      "source": [
        "# Converting the corpus into bag-of-words\n",
        "cv = CountVectorizer(max_features = 8000)\n",
        "X = cv.fit_transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o06bP9FJEaMU",
        "outputId": "11cecfe6-02b7-41a4-e2b5-c93f63276f58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12836, 8000)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVzmJ0MIbZfL",
        "outputId": "04cf6d76-710d-45d5-f75e-3550e7e2e0f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['label', 'statement', 'subject', 'speaker', 'job', 'state', 'party',\n",
              "       'barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c',\n",
              "       'pants_on_fire_c', 'venue'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCqMgDpiLDhu"
      },
      "outputs": [],
      "source": [
        "# Selecting the columns 'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c'\n",
        "label_cols = ['barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c',\n",
        "       'pants_on_fire_c']\n",
        "x_train2 = train[label_cols]\n",
        "x_val2 = val[label_cols]\n",
        "x_test2 = test[label_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QglKXzA_w6DH"
      },
      "outputs": [],
      "source": [
        "# Stacking x_train and x_train2 horizontally\n",
        "x_train_bow = np.hstack((X[:len(x_train)], x_train2))\n",
        "x_val_bow = np.hstack((X[len(x_train):len(x_train)+len(x_val)], x_val2))\n",
        "x_test_bow = np.hstack((X[len(x_train)+len(x_val):], x_test2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3pskgViw99U",
        "outputId": "f448eb8d-c6f4-4454-eb50-521e78efc9ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 8005)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "x_train_bow.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDiJL4Y_bZfN"
      },
      "source": [
        "## Use of Glove Embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwlpQD25bZfN"
      },
      "source": [
        "download glove embeddings from 'https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip'\n",
        "and place in your current working folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Q1oyDbbZfN",
        "outputId": "3e35fcb1-5b1a-4e45-89b0-b04ab963109b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/SMAI/Assignment 3/glove.6B.zip\n",
            "  inflating: glove/glove.6B.50d.txt  \n",
            "  inflating: glove/glove.6B.100d.txt  \n",
            "  inflating: glove/glove.6B.200d.txt  \n",
            "  inflating: glove/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/gdrive/MyDrive/SMAI/Assignment 3/glove.6B.zip\" -d \"glove\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nYEsz6HbZfO"
      },
      "outputs": [],
      "source": [
        "emmbed_dict = {}\n",
        "with open('glove/glove.6B.200d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    emmbed_dict[word]=vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeNksta3bZfO"
      },
      "outputs": [],
      "source": [
        "emmbed_dict['oov'] = np.zeros(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93XKAoV5bZfQ"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxqiFkVMbZfR",
        "outputId": "ad4072d8-5da0-4362-f4e0-4b9a15f5bb92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "nltk.download('punkt')\n",
        "def dataPreprocessing_glove(data):\n",
        "    corpus = []\n",
        "    # Missing values\n",
        "    data[\"job\"].fillna(\"no-job\", inplace = True)\n",
        "    data[\"state\"].fillna(\"no-state\", inplace = True)\n",
        "\n",
        "    for x in range(data.shape[0]):\n",
        "        statement = re.sub('[^a-zA-Z]', ' ', data['statement'][x]) # Removing all numbers and special characters\n",
        "        statement = statement.lower() # Converting uppercase to lowercase\n",
        "        statement = word_tokenize(statement)\n",
        "\n",
        "        embed_statement = []\n",
        "        for w in statement:\n",
        "            if w in emmbed_dict:\n",
        "                embed_statement.append(emmbed_dict[w])\n",
        "            else:\n",
        "                embed_statement.append(emmbed_dict['oov'])\n",
        "         \n",
        "        # bonus: Think how you can encode the below features(hint: look upon label encoding or training your own word2vec or any other embedding model)\n",
        "    \n",
        "#         subject = data['subject'][x].replace(',', ' ')\n",
        "#         speaker = data['speaker'][x]\n",
        "#         job = data['job'][x].lower()\n",
        "#         # job = job.replace(' ', '-')\n",
        "#         state = data['state'][x].lower()\n",
        "#         party = data['party'][x].lower()\n",
        "        corpus.append(embed_statement)\n",
        "    corpus = np.array(corpus)\n",
        "    corpus=pad_sequences(corpus,padding='pre',maxlen=40)\n",
        "\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hFCMOXrbZfS",
        "outputId": "6f5ec464-b7a0-4333-d3b0-1a9f8913c912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "x_train_glove = dataPreprocessing_glove(train)\n",
        "x_val_glove = dataPreprocessing_glove(val) \n",
        "x_test_glove = dataPreprocessing_glove(test) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_glove=x_train_glove.reshape(x_train_glove.shape[0],8000)\n",
        "x_val_glove=x_val_glove.reshape(x_val_glove.shape[0],8000)\n",
        "x_test_glove=x_test_glove.reshape(x_test_glove.shape[0],8000)"
      ],
      "metadata": {
        "id": "yktVBv5URFSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeqZr6LtbZfT"
      },
      "outputs": [],
      "source": [
        "x_train_glove = np.hstack((x_train_glove, x_train2))\n",
        "x_val_glove = np.hstack((x_val_glove, x_val2))\n",
        "x_test_glove = np.hstack((x_test_glove, x_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiDppvxMbZfT"
      },
      "source": [
        "## Use of bert embeddings\n",
        "note: we used our pre-processed code for bow which has the attributed appended to end the end of sentence. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zamJvyFHbZfU"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "x_train_bert = np.hstack((model.encode(x_train), x_train2))\n",
        "x_val_bert = np.hstack((model.encode(x_val), x_val2))\n",
        "x_test_bert = np.hstack((model.encode(x_test), x_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_CUHqb2bZfV"
      },
      "source": [
        "Now use the above 3 types of embedded inputs(bow, glove, bert embeddings) for the 2 classification tasks and compare their outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmavEzWHrTC8"
      },
      "source": [
        "# Six-way classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAhr39Aq41J"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJwZwMXANg9_"
      },
      "outputs": [],
      "source": [
        "num_classes = 6\n",
        "# Preprocessing function for the labels\n",
        "def categorize(data):\n",
        "    y = data[\"label\"].tolist()\n",
        "\n",
        "    # Encoding the Dependent Variable\n",
        "    labelencoder_y = LabelEncoder()\n",
        "    y = labelencoder_y.fit_transform(y)\n",
        "\n",
        "    # Converting to binary class matrix\n",
        "    y = np_utils.to_categorical(y, num_classes)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIKTUSM3MJ-u"
      },
      "outputs": [],
      "source": [
        "y_train_six_way = categorize(train)\n",
        "y_test_six_way = categorize(test)\n",
        "y_val_six_way = categorize(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOQcpmwqbZfW"
      },
      "source": [
        "Build a model and pass bow, glove and bert embedded inputs: x_train_bow, x_train_glove, x_train_bert(similarly validate for val and report results on test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y-dusAUolnI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_bag_of_words_6_way_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "\n",
        "  model.add(Dense(6, activation='softmax'))\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "J2rT3eLSdW83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def define_glove_6_way_model(shapes):\n",
        "    input = Input(shape=shapes)\n",
        "    ip_layer1=keras.layers.Conv1D(16,4,padding=\"same\",activation='relu')(input)\n",
        "    \n",
        "    ip_layer1=keras.layers.MaxPooling1D(pool_size=2,strides=1,padding='same')(ip_layer1)\n",
        "    LSTM_Layer_1 = LSTM(128,return_sequences=True)(ip_layer1)\n",
        "    LSTM_Layer_2 = LSTM(64)(LSTM_Layer_1)\n",
        "    dense_layer = Dense(6, activation='sigmoid')(LSTM_Layer_2)\n",
        "    model= Model(inputs=input, outputs=dense_layer)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "f2J0he7of6SA"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_bag_of_words_binary_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "AasVHa03Qh2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words_6_way_model = define_bag_of_words_6_way_model()\n",
        "es = EarlyStopping(monitor=\"val_accuracy\",mode=\"auto\",verbose=1,patience=3,restore_best_weights=True)\n",
        "history = bag_of_words_6_way_model.fit(x_train_bow, y_train_six_way,batch_size=32,validation_data=(x_val_bow,y_val_six_way),epochs=10,callbacks=[es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJvkx5ZcKgwt",
        "outputId": "a6ab1b85-8602-42b1-b9d1-41871540cf10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 15s 47ms/step - loss: 1.7348 - accuracy: 0.2563 - val_loss: 1.6518 - val_accuracy: 0.3481\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 16s 50ms/step - loss: 1.5248 - accuracy: 0.3881 - val_loss: 1.4972 - val_accuracy: 0.3738\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 15s 46ms/step - loss: 1.4140 - accuracy: 0.4102 - val_loss: 1.4038 - val_accuracy: 0.3941\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 15s 46ms/step - loss: 1.3313 - accuracy: 0.4339 - val_loss: 1.3880 - val_accuracy: 0.4034\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 14s 44ms/step - loss: 1.2730 - accuracy: 0.4531 - val_loss: 1.3701 - val_accuracy: 0.4050\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - 15s 46ms/step - loss: 1.2459 - accuracy: 0.4591 - val_loss: 1.4323 - val_accuracy: 0.3801\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - 15s 46ms/step - loss: 1.1937 - accuracy: 0.4829 - val_loss: 1.4510 - val_accuracy: 0.3738\n",
            "Epoch 8/10\n",
            "320/321 [============================>.] - ETA: 0s - loss: 1.1515 - accuracy: 0.4952Restoring model weights from the end of the best epoch: 5.\n",
            "321/321 [==============================] - 15s 46ms/step - loss: 1.1521 - accuracy: 0.4951 - val_loss: 1.4874 - val_accuracy: 0.3847\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = bag_of_words_6_way_model.evaluate(x_test_bow,y_test_six_way)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOiFY5s9nlPo",
        "outputId": "0df4fb3b-40a4-442b-f261-d9e0f7c0fee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 15ms/step - loss: 1.3884 - accuracy: 0.4147\n",
            "0.41465315222740173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,x):\n",
        "  y = model.predict(x)\n",
        "  predictions=[]\n",
        "  for i in y:\n",
        "    a = np.zeros(6)\n",
        "    a[np.argmax(i,0)]=1\n",
        "    predictions.append(a)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "-gxDZv5kuhe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report_multilabel_metrics(model,x,y):\n",
        "  predictions = predict(model,x)\n",
        "  cm = multilabel_confusion_matrix(y, predictions)\n",
        "  print(\"Confusion Matrix\\n\",cm)\n",
        "  print(\"Accuracy:\",accuracy_score(y, predictions))\n",
        "  print(\"F1 score:\",f1_score(y, predictions,average='weighted'))"
      ],
      "metadata": {
        "id": "qGfUmNn6qN-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Report for Training data\")\n",
        "report_multilabel_metrics(bag_of_words_6_way_model,x_train_bow, y_train_six_way)\n",
        "print(\"============================\")\n",
        "print(\"Report for Validation data\")\n",
        "report_multilabel_metrics(bag_of_words_6_way_model,x_val_bow,y_val_six_way)\n",
        "print(\"============================\")\n",
        "print(\"Report for Test data\")\n",
        "report_multilabel_metrics(bag_of_words_6_way_model,x_test_bow,y_test_six_way)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlEl9P9xrudl",
        "outputId": "07bda628-fa81-433b-9c18-90a321531ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report for Training data\n",
            "Confusion Matrix\n",
            " [[[7813  458]\n",
            "  [1142  856]]\n",
            "\n",
            " [[8580    6]\n",
            "  [1257  426]]\n",
            "\n",
            " [[8196  416]\n",
            "  [ 945  712]]\n",
            "\n",
            " [[4543 3603]\n",
            "  [ 377 1746]]\n",
            "\n",
            " [[7567  736]\n",
            "  [1054  912]]\n",
            "\n",
            " [[9338   89]\n",
            "  [ 533  309]]]\n",
            "Accuracy: 0.4831044892394586\n",
            "F1 score: 0.48320785869246236\n",
            "============================\n",
            "Report for Validation data\n",
            "Confusion Matrix\n",
            " [[[ 956   65]\n",
            "  [ 163  100]]\n",
            "\n",
            " [[1109    6]\n",
            "  [ 140   29]]\n",
            "\n",
            " [[ 971   76]\n",
            "  [ 154   83]]\n",
            "\n",
            " [[ 537  499]\n",
            "  [  58  190]]\n",
            "\n",
            " [[ 939   94]\n",
            "  [ 160   91]]\n",
            "\n",
            " [[1144   24]\n",
            "  [  89   27]]]\n",
            "Accuracy: 0.40498442367601245\n",
            "F1 score: 0.39965359772247966\n",
            "============================\n",
            "Report for Test data\n",
            "Confusion Matrix\n",
            " [[[ 958   75]\n",
            "  [ 154   96]]\n",
            "\n",
            " [[1069    3]\n",
            "  [ 178   33]]\n",
            "\n",
            " [[ 994   75]\n",
            "  [ 142   72]]\n",
            "\n",
            " [[ 540  476]\n",
            "  [  61  206]]\n",
            "\n",
            " [[ 929  105]\n",
            "  [ 157   92]]\n",
            "\n",
            " [[1174   17]\n",
            "  [  59   33]]]\n",
            "Accuracy: 0.4146531566640686\n",
            "F1 score: 0.4030868441048496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_glove1 = np.expand_dims(x_train_glove,-1)\n",
        "glove_6_way_model = define_glove_6_way_model(x_train_glove1.shape[1:])\n",
        "es = EarlyStopping(monitor=\"val_accuracy\",mode=\"auto\",verbose=1,patience=3,restore_best_weights=True)\n",
        "history = glove_6_way_model.fit(x_train_glove, y_train_six_way,batch_size=32,validation_data=(x_val_glove,y_val_six_way),epochs=10,callbacks=[es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vs95JiigIct",
        "outputId": "40f9d397-0672-4698-b6bb-274556e3bc73"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.4413 - acc: 0.2260WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 175s 536ms/step - loss: 0.4413 - acc: 0.2260 - val_loss: 0.4270 - val_acc: 0.3131\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3778 - acc: 0.4253WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 171s 533ms/step - loss: 0.3778 - acc: 0.4253 - val_loss: 0.3546 - val_acc: 0.4385\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3478 - acc: 0.4522WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 171s 532ms/step - loss: 0.3478 - acc: 0.4522 - val_loss: 0.3442 - val_acc: 0.4424\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3408 - acc: 0.4503WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 174s 542ms/step - loss: 0.3408 - acc: 0.4503 - val_loss: 0.3393 - val_acc: 0.4540\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3377 - acc: 0.4558WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 173s 538ms/step - loss: 0.3377 - acc: 0.4558 - val_loss: 0.3371 - val_acc: 0.4626\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3364 - acc: 0.4534WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 171s 534ms/step - loss: 0.3364 - acc: 0.4534 - val_loss: 0.3384 - val_acc: 0.4603\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3351 - acc: 0.4551WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 171s 533ms/step - loss: 0.3351 - acc: 0.4551 - val_loss: 0.3359 - val_acc: 0.4416\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3341 - acc: 0.4552WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 174s 544ms/step - loss: 0.3341 - acc: 0.4552 - val_loss: 0.3336 - val_acc: 0.4751\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3336 - acc: 0.4571WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 172s 534ms/step - loss: 0.3336 - acc: 0.4571 - val_loss: 0.3334 - val_acc: 0.4665\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.3330 - acc: 0.4577WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 174s 542ms/step - loss: 0.3330 - acc: 0.4577 - val_loss: 0.3324 - val_acc: 0.4611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = glove_6_way_model.evaluate(x_test_glove,y_test_six_way)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIBHpjkOgNH2",
        "outputId": "efb5ddb7-f4e3-4d87-9e26-92a224fa473b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 9s 223ms/step - loss: 0.3402 - acc: 0.4489\n",
            "0.4489477872848511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Report for Training data\")\n",
        "report_multilabel_metrics(glove_6_way_model,x_train_glove, y_train_six_way)\n",
        "print(\"============================\")\n",
        "print(\"Report for Validation data\")\n",
        "report_multilabel_metrics(glove_6_way_model,x_val_glove,y_val_six_way)\n",
        "print(\"============================\")\n",
        "print(\"Report for Test data\")\n",
        "report_multilabel_metrics(glove_6_way_model,x_test_glove,y_test_six_way)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdM8KCGhg14t",
        "outputId": "17457da8-6f35-4894-bfb6-2daefa4894d2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report for Training data\n",
            "Confusion Matrix\n",
            " [[[7332  939]\n",
            "  [1052  946]]\n",
            "\n",
            " [[8575   11]\n",
            "  [1354  329]]\n",
            "\n",
            " [[7736  876]\n",
            "  [ 953  704]]\n",
            "\n",
            " [[6603 1543]\n",
            "  [ 980 1143]]\n",
            "\n",
            " [[6348 1955]\n",
            "  [ 681 1285]]\n",
            "\n",
            " [[9230  197]\n",
            "  [ 501  341]]]\n",
            "Accuracy: 0.4623624500925114\n",
            "F1 score: 0.451604935888765\n",
            "============================\n",
            "Report for Validation data\n",
            "Confusion Matrix\n",
            " [[[ 907  114]\n",
            "  [ 146  117]]\n",
            "\n",
            " [[1115    0]\n",
            "  [ 138   31]]\n",
            "\n",
            " [[ 948   99]\n",
            "  [ 135  102]]\n",
            "\n",
            " [[ 821  215]\n",
            "  [ 116  132]]\n",
            "\n",
            " [[ 795  238]\n",
            "  [  92  159]]\n",
            "\n",
            " [[1142   26]\n",
            "  [  65   51]]]\n",
            "Accuracy: 0.46105919003115264\n",
            "F1 score: 0.4531706458021525\n",
            "============================\n",
            "Report for Test data\n",
            "Confusion Matrix\n",
            " [[[ 915  118]\n",
            "  [ 133  117]]\n",
            "\n",
            " [[1069    3]\n",
            "  [ 178   33]]\n",
            "\n",
            " [[ 962  107]\n",
            "  [ 126   88]]\n",
            "\n",
            " [[ 817  199]\n",
            "  [ 130  137]]\n",
            "\n",
            " [[ 778  256]\n",
            "  [  95  154]]\n",
            "\n",
            " [[1167   24]\n",
            "  [  45   47]]]\n",
            "Accuracy: 0.4489477786438036\n",
            "F1 score: 0.43635391164489756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_bert1 = np.expand_dims(x_train_bert,-1)\n",
        "bert_6_way_model = define_glove_6_way_model(x_train_bert1.shape[1:])\n",
        "es = EarlyStopping(monitor=\"val_accuracy\",mode=\"auto\",verbose=1,patience=3,restore_best_weights=True)\n",
        "history = bert_6_way_model.fit(x_train_bert, y_train_six_way,batch_size=32,validation_data=(x_val_bert,y_val_six_way),epochs=10,callbacks=[es])\n"
      ],
      "metadata": {
        "id": "jbPYhB54rDsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = bert_6_way_model.evaluate(x_test_bert,y_test_six_way)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "DnsicRcbrhvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Report for Training data\")\n",
        "report_multilabel_metrics(bert_6_way_model,x_train_bert, y_train_six_way)\n",
        "print(\"============================\")\n",
        "print(\"Report for Validation data\")\n",
        "report_multilabel_metrics(bert_6_way_model,x_val_bert,y_val_six_way)\n",
        "print(\"============================\")\n",
        "print(\"Report for Test data\")\n",
        "report_multilabel_metrics(bert_6_way_model,x_test_bert,y_test_six_way)"
      ],
      "metadata": {
        "id": "gb9TI_TmrnUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHTXwKppbZfW"
      },
      "outputs": [],
      "source": [
        "## write your code here\n",
        "# Initialize hyperparameters\n",
        "# Create model\n",
        "# train\n",
        "# test\n",
        "# report accuracy, f1-score and confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctoTOw2uIK1G"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJUrQ1SrEBa"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA3wQH1JinNx"
      },
      "outputs": [],
      "source": [
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk-q1zwVF5KZ"
      },
      "outputs": [],
      "source": [
        "# Function for preprocessing labels\n",
        "def dataPreprocessingBinary(data):\n",
        "    y = data[\"label\"].tolist()\n",
        "\n",
        "    # Changing the 'half-true', 'mostly-true', barely-true', 'pants-fire' labels to True/False for Binary Classification\n",
        "    for x in range(len(y)):\n",
        "        if(y[x] == 'half-true'):\n",
        "            y[x] = 'True'\n",
        "        elif(y[x] == 'mostly-true'):\n",
        "            y[x] = 'True'\n",
        "        elif(y[x] == 'barely-true'):\n",
        "            y[x] = 'False'\n",
        "        elif(y[x] == 'pants-fire'):\n",
        "            y[x] = 'False'\n",
        "\n",
        "    # Converting the lables into binary class matrix\n",
        "    labelencoder_y = LabelEncoder()\n",
        "    y = labelencoder_y.fit_transform(y)\n",
        "    y = np_utils.to_categorical(y, num_classes)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REu1ue0xbuqp"
      },
      "outputs": [],
      "source": [
        "y_train_binary = dataPreprocessingBinary(train)\n",
        "y_test_binary = dataPreprocessingBinary(test)\n",
        "y_val_binary = dataPreprocessingBinary(val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def report_metrics(model,x,y):\n",
        "  y_pred = model.predict(x)\n",
        "  predictions=[]\n",
        "  for i in y_pred:\n",
        "    a = np.zeros(2)\n",
        "    a[np.argmax(i,0)]=1\n",
        "    predictions.append(a)\n",
        "    \n",
        "  cm = multilabel_confusion_matrix(y, predictions)\n",
        "  print(\"Confusion Matrix\\n\",cm)\n",
        "  print(\"Accuracy:\",accuracy_score(y, predictions))\n",
        "  print(\"F1 score:\",f1_score(y, predictions,average=None))"
      ],
      "metadata": {
        "id": "u_i8unO6SSpw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words_binary_model = define_bag_of_words_binary_model()\n",
        "es = EarlyStopping(monitor=\"val_accuracy\",mode=\"auto\",verbose=1,patience=3,restore_best_weights=True)\n",
        "history = bag_of_words_binary_model.fit(x_train_bow, y_train_binary,batch_size=32,validation_data=(x_val_bow,y_val_binary),epochs=10,callbacks=[es])\n"
      ],
      "metadata": {
        "id": "3LKGItpGHfFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b8a1bc-0bdb-45d5-ee12-e4a74e7a640a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - 4s 6ms/step - loss: 0.6644 - accuracy: 0.6098 - val_loss: 0.5980 - val_accuracy: 0.6830\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - 2s 5ms/step - loss: 0.5480 - accuracy: 0.7254 - val_loss: 0.5217 - val_accuracy: 0.7126\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.5080 - accuracy: 0.7302 - val_loss: 0.5230 - val_accuracy: 0.7165\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - 3s 8ms/step - loss: 0.4713 - accuracy: 0.7467 - val_loss: 0.5169 - val_accuracy: 0.7142\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - 2s 7ms/step - loss: 0.4502 - accuracy: 0.7601 - val_loss: 0.5314 - val_accuracy: 0.7150\n",
            "Epoch 6/10\n",
            "311/321 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.7746Restoring model weights from the end of the best epoch: 3.\n",
            "321/321 [==============================] - 2s 5ms/step - loss: 0.4246 - accuracy: 0.7737 - val_loss: 0.5553 - val_accuracy: 0.7079\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = bag_of_words_binary_model.evaluate(x_test_bow,y_test_binary)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZxFcJZFR927",
        "outputId": "837abf24-3fd2-4688-8160-be8942144eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7405\n",
            "0.7404520511627197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Report for Training data\")\n",
        "report_metrics(bag_of_words_binary_model,x_train_bow, y_train_binary)\n",
        "print(\"============================\")\n",
        "print(\"Report for Validation data\")\n",
        "report_metrics(bag_of_words_binary_model,x_val_bow,y_val_binary)\n",
        "print(\"============================\")\n",
        "print(\"Report for Test data\")\n",
        "report_metrics(bag_of_words_binary_model,x_test_bow,y_test_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvyr6BO7SCYO",
        "outputId": "fa3d560d-f117-407a-a91f-4d0a46cfc335"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report for Training data\n",
            "Confusion Matrix\n",
            " [[[5027  745]\n",
            "  [1753 2744]]\n",
            "\n",
            " [[2744 1753]\n",
            "  [ 745 5027]]]\n",
            "Accuracy: 0.7567435972343948\n",
            "F1 score: [0.6872026  0.80098789]\n",
            "============================\n",
            "Report for Validation data\n",
            "Confusion Matrix\n",
            " [[[566 102]\n",
            "  [262 354]]\n",
            "\n",
            " [[354 262]\n",
            "  [102 566]]]\n",
            "Accuracy: 0.7165109034267912\n",
            "F1 score: [0.66044776 0.75668449]\n",
            "============================\n",
            "Report for Test data\n",
            "Confusion Matrix\n",
            " [[[624 103]\n",
            "  [230 326]]\n",
            "\n",
            " [[326 230]\n",
            "  [103 624]]]\n",
            "Accuracy: 0.7404520654715511\n",
            "F1 score: [0.66192893 0.78937381]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "def define_glove_binary_model(shapes):\n",
        "    input = Input(shape=shapes)\n",
        "    ip_layer1=keras.layers.Conv1D(16,4,padding=\"same\",activation='relu')(input)\n",
        "    \n",
        "    ip_layer1=keras.layers.MaxPooling1D(pool_size=2,strides=1,padding='same')(ip_layer1)\n",
        "    LSTM_Layer_1 = LSTM(128,return_sequences=True)(ip_layer1)\n",
        "    LSTM_Layer_2 = LSTM(64)(LSTM_Layer_1)\n",
        "    dense_layer = Dense(2, activation='sigmoid')(LSTM_Layer_2)\n",
        "    model= Model(inputs=input, outputs=dense_layer)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "zRQeejQXcOIr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_glove1 = np.expand_dims(x_train_glove,-1)\n",
        "glove_binary_model = define_glove_binary_model(x_train_glove1.shape[1:])\n",
        "es = EarlyStopping(monitor=\"val_accuracy\",mode=\"auto\",verbose=1,patience=3,restore_best_weights=True)\n",
        "history = glove_binary_model.fit(x_train_glove, y_train_binary,batch_size=32,validation_data=(x_val_glove,y_val_binary),epochs=10,callbacks=[es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESr3n1ttdE4o",
        "outputId": "170d034b-86fe-42a4-8d6c-d4edc626784f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.6349 - acc: 0.6421WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 186s 542ms/step - loss: 0.6349 - acc: 0.6421 - val_loss: 0.5871 - val_acc: 0.6970\n",
            "Epoch 2/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.5518 - acc: 0.7086WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 172s 537ms/step - loss: 0.5518 - acc: 0.7086 - val_loss: 0.5346 - val_acc: 0.6970\n",
            "Epoch 3/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.5194 - acc: 0.7244WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 172s 537ms/step - loss: 0.5194 - acc: 0.7244 - val_loss: 0.5252 - val_acc: 0.6978\n",
            "Epoch 4/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.5085 - acc: 0.7289WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 173s 540ms/step - loss: 0.5085 - acc: 0.7289 - val_loss: 0.5062 - val_acc: 0.7040\n",
            "Epoch 5/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.5036 - acc: 0.7285WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 173s 539ms/step - loss: 0.5036 - acc: 0.7285 - val_loss: 0.5128 - val_acc: 0.7111\n",
            "Epoch 6/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.5018 - acc: 0.7327WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 172s 537ms/step - loss: 0.5018 - acc: 0.7327 - val_loss: 0.4979 - val_acc: 0.7111\n",
            "Epoch 7/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.5007 - acc: 0.7328WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 171s 534ms/step - loss: 0.5007 - acc: 0.7328 - val_loss: 0.4979 - val_acc: 0.7165\n",
            "Epoch 8/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.4988 - acc: 0.7329WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 172s 537ms/step - loss: 0.4988 - acc: 0.7329 - val_loss: 0.5069 - val_acc: 0.7103\n",
            "Epoch 9/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.4990 - acc: 0.7328WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 170s 528ms/step - loss: 0.4990 - acc: 0.7328 - val_loss: 0.5026 - val_acc: 0.7064\n",
            "Epoch 10/10\n",
            "321/321 [==============================] - ETA: 0s - loss: 0.4993 - acc: 0.7317WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "321/321 [==============================] - 170s 528ms/step - loss: 0.4993 - acc: 0.7317 - val_loss: 0.5025 - val_acc: 0.7079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = glove_binary_model.evaluate(x_test_glove,y_test_binary)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMR59w8hdT8F",
        "outputId": "f41db2da-a372-436b-962a-58152ca126ce"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 9s 218ms/step - loss: 0.5080 - acc: 0.7327\n",
            "0.7326578497886658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Report for Training data\")\n",
        "report_metrics(glove_binary_model,x_train_glove, y_train_binary)\n",
        "print(\"============================\")\n",
        "print(\"Report for Validation data\")\n",
        "report_metrics(glove_binary_model,x_val_glove,y_val_binary)\n",
        "print(\"============================\")\n",
        "print(\"Report for Test data\")\n",
        "report_metrics(glove_binary_model,x_test_glove,y_test_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIhAUtU4eETy",
        "outputId": "105ff1ba-71cd-4cae-d2e0-5fd7b9995221"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report for Training data\n",
            "Confusion Matrix\n",
            " [[[4854  918]\n",
            "  [1793 2704]]\n",
            "\n",
            " [[2704 1793]\n",
            "  [ 918 4854]]]\n",
            "Accuracy: 0.7360015580874476\n",
            "F1 score: [0.66609188 0.78170545]\n",
            "============================\n",
            "Report for Validation data\n",
            "Confusion Matrix\n",
            " [[[557 111]\n",
            "  [264 352]]\n",
            "\n",
            " [[352 264]\n",
            "  [111 557]]]\n",
            "Accuracy: 0.7079439252336449\n",
            "F1 score: [0.65245598 0.74815312]\n",
            "============================\n",
            "Report for Test data\n",
            "Confusion Matrix\n",
            " [[[608 119]\n",
            "  [224 332]]\n",
            "\n",
            " [[332 224]\n",
            "  [119 608]]]\n",
            "Accuracy: 0.7326578332034295\n",
            "F1 score: [0.65938431 0.77998717]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI4PIrgR01Sd"
      },
      "source": [
        "## Model\n",
        "Build a model and pass bow, glove and bert embedded inputs: x_train_bow, x_train_glove, x_train_bert(similarly validate for val and report results on test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J0inPaQb-8Y"
      },
      "outputs": [],
      "source": [
        "## write your code here\n",
        "# Initialize hyperparameters\n",
        "# Create model\n",
        "# train\n",
        "# test\n",
        "# report accuracy, f1-score and confusion matrix"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2021201005_Assignment3_Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}